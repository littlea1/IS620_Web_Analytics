{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam Classification with SVC and sklearn\n",
    "### Assignment week 10/11 - jdeblase\n",
    "\n",
    "It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  Here is one example of such data:  http://archive.ics.uci.edu/ml/datasets/Spambase\n",
    "\n",
    "For this project, you can use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment I will be using the Spambase database at the url link to predict whether emails are spam or not spam. The classifier I will use is the Support Vector Classifier (SVM) class found in the svm module in sklearn, along with several utility functions and classes found in the framework.\n",
    "\n",
    "The first step is to load the dataset and seperate the response variable from the rest of the predictor variables. All the predictor variables have been normalized already as continous real or integer values. The response variable is nominal, 1 for spam, 0 for non-spam. More information on the dataset can be found <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names\"> here</a>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## load data\n",
    "all_data = pd.read_csv(\"spambase/spambase.data\",header=None).as_matrix()\n",
    "x = all_data[:,:-1]\n",
    "y = all_data[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is split the data into training and test sets. This can be done manually, but here we use sklearn's train_test_split() function to handle shuffling and randomizing the samples. The size of the test set is set to 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split data into test and train arrays for sklearn\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "A basic estimator is set using the SVC class. We will leave the kernel function to its default setting of 'rbf', and leave 'C' and 'gamma' at their default settings as well. \n",
    "\n",
    "After we train the model, we will use it to predict the x test set and evaluate its performance with sklearn's confusion matrix and classification report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic fit and test\n",
    "svm_est = svm.SVC()\n",
    "svm_est.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = svm_est.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[471,  91],\n",
       "       [ 77, 282]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      0.84      0.85       562\n",
      "        1.0       0.76      0.79      0.77       359\n",
      "\n",
      "avg / total       0.82      0.82      0.82       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the confusion matrix that our basic model correctly predicted 753 emails, with 77 false positives (Type I errors) and 91 false negatives(Type II errors). Both the precision and recall were 0.82, meaning that the model returned 82% percent of the results correctly, and that the model had a high rate of relevance.\n",
    "\n",
    "We can improve the model even further by using sklearn's cross validation iterator and Grid Search to exhaustively tune the hyper-parameters of 'C' and 'gamma'. The following code references material from sklearn's <a href=\"http://scikit-learn.org/stable/modules/cross_validation.html\"> documentation </a> on cross validation techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using CV and fine tuning on hyper-parameters to improve model\n",
    "\n",
    "# first rebuild training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "\n",
    "# create an iterator for CV\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "cv_iter = ShuffleSplit(len(x_train),n_iter=5,test_size=0.2)\n",
    "# cross validate with increasing 'C' and decreasing 'gamma' levels\n",
    "params = [{'C':[1,10,100,1000,10000],'gamma':[0.01,0.001,0.0001,0.00001]}] \n",
    "\n",
    "clf = GridSearchCV(estimator=svm_est, cv=cv_iter, param_grid=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We now fit the new model with the training sets and use the parameters for the best estimator from the clf_fit to create a new SVC model with fine tuned parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=1e-05, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_svm_est = svm.SVC(C=clf.best_estimator_.C,gamma=clf.best_estimator_.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=1e-05, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_svm_est.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now make predictions with the tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = new_svm_est.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[509  29]\n",
      " [ 51 332]]\n"
     ]
    }
   ],
   "source": [
    "print confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.95      0.93       538\n",
      "        1.0       0.92      0.87      0.89       383\n",
      "\n",
      "avg / total       0.91      0.91      0.91       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can see that this improves the model significantly. The model now produces 841 accurate results, with 51 false positives and 29 false negatives. This results in a hihgly relevant model that accurately predicts spam 91% of the time. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [graph_lab_env]",
   "language": "python",
   "name": "Python [graph_lab_env]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
